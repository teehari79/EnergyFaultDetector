{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# CARE Score and Care2CompareDataset usage\n",
    "\n",
    "This notebook shows how to apply the CAREScore to the CARE2Compare dataset ([zenodo](https://doi.org/10.5281/zenodo.10958774)).\n",
    "Contents of this notebook:\n",
    "\n",
    "1. Using the Care2CompareDataset class to load the CARE to compare dataset from zenodo.\n",
    "2. Using the CAREScore to evaluate a model on the dataset.\n",
    "3. Recreating the results of the CARE paper.\n",
    "4. Using Care2CompareDataset and CARE-Score for other datasets."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "source": [
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from energy_fault_detector.fault_detector import FaultDetector\n",
    "from energy_fault_detector.config import Config\n",
    "from energy_fault_detector.evaluation import CAREScore, Care2CompareDataset"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "75ac0a42f7c2f795",
   "metadata": {},
   "source": [
    "data_dir = Path('..') / '..' / 'Care_To_Compare_v6'"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "70f2af66920ba09b",
   "metadata": {},
   "source": [
    "c2c = Care2CompareDataset(path=data_dir, download_dataset=False)  # If you have not downloaded the dataset yet, set download_dataset to True"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "8a1422f3e62850ab",
   "metadata": {},
   "source": [
    "c2c.event_info_all"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "48309c102d52aeb0",
   "metadata": {},
   "source": [
    "# select data for a specific event\n",
    "x, y = c2c.get_dataset_for_event(0, statistics=['average', 'std_dev'])\n",
    "x.head()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "3b5d3d886e74bc38",
   "metadata": {},
   "source": [
    "### Create model per event and evaluate"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "c2c = Care2CompareDataset(data_dir)\n",
    "index_column = 'id'  # us time_stamp as index column if you are using the TimestampTransformer\n",
    "suffix = ''\n",
    "\n",
    "configs = {\n",
    "    'A': Config('c2c_configs/windfarm_A.yaml'),\n",
    "    'B': Config('c2c_configs/windfarm_B.yaml'),\n",
    "    'C': Config('c2c_configs/windfarm_C.yaml'),\n",
    "}\n",
    "\n",
    "result_files = {\n",
    "    'A': f'results_A{suffix}.csv',\n",
    "    'B': f'results_B{suffix}.csv',\n",
    "    'C': f'results_C{suffix}.csv',\n",
    "}\n",
    "\n",
    "# For WF A we cannot use the normal index to filter the events, as this would remove complete anomalous events (these are not based on actual SCADA Status codes).\n",
    "# For WF B and C this info is however useful, and it would not be interesting to detect non-actionable anomalies (normal_index=False)\n",
    "ignore_normal_idx = {\n",
    "    'A': True,\n",
    "    'B': False,\n",
    "    'C': False,\n",
    "}\n",
    "\n",
    "# Initialize CARE-Score\n",
    "care_score = CAREScore(coverage_beta=0.5, reliability_beta=0.5, anomaly_detection_method='criticality')\n",
    "\n",
    "for wf in ['A', 'B', 'C']:\n",
    "    print('Wind Farm ', wf)\n",
    "    \n",
    "    # update model config\n",
    "    config = configs[wf]\n",
    "    c2c.update_c2c_config(config, wf)\n",
    "    \n",
    "    results_file = result_files[wf]\n",
    "    if os.path.exists(results_file):\n",
    "        care_score.load_evaluated_events(results_file)\n",
    "\n",
    "    event_ids = c2c.event_info_all.loc[c2c.event_info_all['wind_farm'] == wf, 'event_id']\n",
    "    for event_id in event_ids:\n",
    "\n",
    "        if not care_score.evaluated_events.empty and event_id in care_score.evaluated_events['event_id'].values:\n",
    "            # skip if already evaluated\n",
    "            continue\n",
    "        \n",
    "        print(\"Evaluating Event\", event_id)\n",
    "        x_train, x_test = c2c.load_event_dataset(event_id=event_id, index_column=index_column)\n",
    "        # create normal index\n",
    "        y_train = x_train['status_type_id'] == 0\n",
    "        y_test = x_test['status_type_id'] == 0\n",
    "        \n",
    "        # drop unnecessary features\n",
    "        x_train = x_train.drop(['asset_id', 'status_type_id', 'time_stamp'], axis=1, errors='ignore')\n",
    "        x_test = x_test.drop(['asset_id', 'status_type_id', 'time_stamp'], axis=1, errors='ignore')\n",
    "        \n",
    "        # create model\n",
    "        model = FaultDetector(config)\n",
    "        # train and predict\n",
    "        train_results = model.fit(sensor_data=x_train, normal_index=y_train, save_models=False)\n",
    "        prediction = model.predict(x_test)\n",
    "        \n",
    "        # evaluate event\n",
    "        event_info = c2c.event_info_all[c2c.event_info_all['event_id'] == event_id]\n",
    "        event_start = event_info['event_start_id'].iloc[0] if index_column == 'id' else event_info['event_start'].iloc[0]\n",
    "        event_end = event_info['event_end_id'].iloc[0] if index_column == 'id' else event_info['event_end'].iloc[0]\n",
    "        care_score.evaluate_event(\n",
    "            event_id=event_id,\n",
    "            event_start=event_start,\n",
    "            event_end=event_end,\n",
    "            event_label=event_info['event_label'].iloc[0],\n",
    "            normal_index=y_test,\n",
    "            predicted_anomalies=prediction.predicted_anomalies['anomaly'],\n",
    "            ignore_normal_index=ignore_normal_idx[wf]\n",
    "        )\n",
    "        \n",
    "        # save evaluated events\n",
    "        care_score.save_evaluated_events(results_file)\n",
    "\n",
    "    # print final score:\n",
    "    print('Final score: ', care_score.get_final_score())"
   ],
   "id": "e9087f75625207d2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# combine results and get final score over all events / wind farms\n",
    "all_evaluations = pd.concat([pd.read_csv(f'results_{wf}{suffix}.csv') for wf in ['A', 'B', 'C']])\n",
    "all_evaluations.to_csv(f'results_all{suffix}.csv', index=False)\n",
    "care_score.load_evaluated_events(f'results_all{suffix}.csv')\n",
    "\n",
    "print('Wind farm A:')\n",
    "print(\n",
    "    care_score.get_final_score(event_selection=c2c.event_info_all.loc[c2c.event_info_all['wind_farm'] == 'A', 'event_id'])\n",
    ")\n",
    "print('Wind farm B:')\n",
    "print(\n",
    "    care_score.get_final_score(event_selection=c2c.event_info_all.loc[c2c.event_info_all['wind_farm'] == 'B', 'event_id'])\n",
    ")\n",
    "print('Wind farm C:')\n",
    "print(\n",
    "    care_score.get_final_score(event_selection=c2c.event_info_all.loc[c2c.event_info_all['wind_farm'] == 'C', 'event_id'])\n",
    ")\n",
    "\n",
    "print('overall')\n",
    "care_score.get_final_score()"
   ],
   "id": "a41c52ce61dd7e06",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "567e27438a2e7df9",
   "metadata": {},
   "source": [
    "### Create model per asset ID and evaluate each event\n",
    "\n",
    "Another option is to create a model for asset ID, by combining the training datasets, instead of creating a model for each event separately.\n",
    "We still evaluate each event separately. Example for WF A:"
   ]
  },
  {
   "cell_type": "code",
   "id": "ac23c5d8fe923863",
   "metadata": {},
   "source": [
    "# model config\n",
    "wf = 'A'\n",
    "config = Config(f'c2c_configs/windfarm_{wf}.yaml')\n",
    "c2c.update_c2c_config(config, wf)\n",
    "care_score = CAREScore(coverage_beta=0.5, reliability_beta=0.5, anomaly_detection_method='criticality')\n",
    "\n",
    "for x_train, asset_id, event_ids in c2c.iter_train_datasets_per_asset(wf):\n",
    "    x_train = x_train.reset_index(drop=True)\n",
    "\n",
    "    # create normal index\n",
    "    y_train = x_train['status_type_id'] == 0\n",
    "    # drop unnecessary features (keep asset ID as a sort of condition)\n",
    "    x_train = x_train.drop(['time_stamp', 'status_type_id'], axis=1)\n",
    "    \n",
    "    # create model\n",
    "    model = FaultDetector(config)\n",
    "    # train and predict\n",
    "    train_results = model.fit(sensor_data=x_train, normal_index=y_train, save_models=False)\n",
    "    \n",
    "    # test and evaluate events for this asset\n",
    "    for event_id in event_ids:\n",
    "        print(event_id)\n",
    "        # test model\n",
    "        x_test = c2c.get_dataset_for_event(event_id=event_id, test_only=True)\n",
    "        y_test = x_test['status_type_id'] == 0\n",
    "        x_test = x_test.drop(['time_stamp', 'asset_id', 'status_type_id'], axis=1)\n",
    "        prediction = model.predict(x_test)\n",
    "        \n",
    "        # evaluate event\n",
    "        event_info = c2c.event_info_all[c2c.event_info_all['event_id'] == event_id]\n",
    "        care_score.evaluate_event(\n",
    "            event_id=event_id,\n",
    "            event_start_id=event_info['event_start_id'].iloc[0],\n",
    "            event_end_id=event_info['event_end_id'].iloc[0],\n",
    "            event_label=event_info['event_label'].iloc[0],\n",
    "            normal_index=y_test,\n",
    "            predicted_anomalies=prediction.predicted_anomalies['anomaly'],\n",
    "            ignore_normal_index=True,\n",
    "        )\n"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "240be4ff7c0b1325",
   "metadata": {},
   "source": [
    "care_score.get_final_score()"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Reproducing results from the Paper\n",
    "To reproduce the results from (https://doi.org/10.3390/data9120138), an additional filter is needed (though only for wind farm C):\n",
    "- determine cut-in and cut-off wind speeds by power curve analysis\n",
    "- Remove potentially anomalous data from the training data:\n",
    "    - Remove rows where the wind speed is outside the normal operation range (below cut-in or above cut-off)\n",
    "    - Remove rows where the power is zero or near zero (e.g. $P < 0.01$)."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# TODO"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# CARE Score and Care2CompareDataset usage on other datasets\n",
    "\n",
    "To use the CARE-Score with other datasets you need the following data:\n",
    "- define events containing anomalous data (the period before an actual fault)\n",
    "- define events containing normal data\n",
    "- For all events there needs to be enough training data beforehand to train an early fault detection model\n",
    "- Ideally you have the same amount of normal and anomalous events\n",
    "\n",
    "Then you can use the `CAREScore` class to calculate the final score:\n",
    "- Create models and get predictions for each event.\n",
    "- Evaluate each event using the `CAREScore.evaluate_event` method\n",
    "- Calculate the CARE score `CAREScore.get_final_score`\n",
    "\n",
    "For each of these events, you need to be able to train a proper model (for example one large model or a model for each event). For the CARE2Compare dataset we assumed 1 year of training data with >=70% normal operation is enough to create a normal behavior model.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
