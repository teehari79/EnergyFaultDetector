{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Example: Hyperparameter optimization with Optuna\n",
    "\n",
    "This notebook introduces 3 examples fÃ¼r hyperparameter optimization based on different optimization objectives.\n",
    "1. Optimizing the Autoencoder reconstruction using the MSE\n",
    "2. Optimizing the FaultDetector classification performance using the Fbeta score\n",
    "3. Optimizing the FaultDetector classification performance using the CARE-score\n",
    "The optimization is done using the [CARE to Compare dataset](https://doi.org/10.5281/zenodo.14958989)\n",
    "\n",
    "For this example you need to install Optuna, which is not contained in the standard requirements of the framework\n",
    "Optuna [docs](https://optuna.readthedocs.io/en/stable/index.html) and [tutorials](https://optuna.readthedocs.io/en/stable/tutorial/index.html)\n",
    "\n",
    "-> Install additional requirements for this example using 'pip notebooks/example_requirements.txt'"
   ],
   "id": "552412b97335ea1c"
  },
  {
   "cell_type": "code",
   "source": [
    "from typing import List\n",
    "\n",
    "import optuna as op\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import fbeta_score\n",
    "\n",
    "from energy_fault_detector.fault_detector import FaultDetector\n",
    "from energy_fault_detector.config import Config\n",
    "from energy_fault_detector.evaluation import CAREScore, Care2CompareDataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "217e454f48a9879b",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "source": [
    "data_path = './Care_To_Compare'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d2e20520349e34e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def update_config(config: Config, feature_descriptions: pd.DataFrame) -> None:\n",
    "    \"\"\"Update config based on provided feature descriptions.\"\"\"\n",
    "\n",
    "    def get_columns(feature_description_selection: pd.DataFrame) -> List[str]:\n",
    "        col_suffix = {\n",
    "            'average': 'avg',\n",
    "            'minimum': 'min',\n",
    "            'maximum': 'max',\n",
    "            'std_dev': 'std'\n",
    "        }\n",
    "        columns = []\n",
    "        for _, row in feature_description_selection.iterrows():\n",
    "            if row.statistics_type == 'average':\n",
    "                # in this case the column can be either sensor_i or sensor_i_avg, so we add both\n",
    "                columns.append(row.sensor_name)\n",
    "            for stat in row.statistics_type.split(','):\n",
    "                columns.append(f'{row.sensor_name}_{col_suffix[stat]}')\n",
    "        return columns\n",
    "\n",
    "    angles = feature_descriptions.loc[feature_descriptions['is_angle']]\n",
    "    to_exclude = feature_descriptions.loc[feature_descriptions['is_counter']]\n",
    "\n",
    "    angle_columns = get_columns(angles)\n",
    "    to_exclude_columns = get_columns(to_exclude)\n",
    "    \n",
    "    config['train']['data_preprocessor']['params']['angles'] = (\n",
    "        config['train']['data_preprocessor']['params'].get('angles', []) + angle_columns\n",
    "    )\n",
    "    config['train']['data_preprocessor']['params']['features_to_exclude'] = (\n",
    "        config['train']['data_preprocessor']['params'].get('features_to_exclude', []) + to_exclude_columns\n",
    "    )\n",
    "    \n",
    "    config.update_config(config.config_dict)\n"
   ],
   "id": "723566d33fa10db6",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "c2c = Care2CompareDataset(data_path)"
   ],
   "id": "ec8c21f059bba3c8",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Optimize autoencoder reconstruction"
   ],
   "id": "99fcaa7054047666"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_config = Config('c2c_configs/windfarm_C.yaml')  # starting point\n",
    "\n",
    "# our test set\n",
    "c2c = Care2CompareDataset(data_path)\n",
    "event_id = 47\n",
    "train_data, normal_index, _, _ = c2c.get_formatted_event_dataset(event_id=event_id, index_column='time_stamp')\n",
    "\n",
    "# speed up for testing\n",
    "N = 10000\n",
    "normal_index = normal_index.iloc[:N]\n",
    "train_data = train_data.iloc[:N]\n",
    "\n",
    "# Create an objective - what should be optimized? --> MSE of the reconstruction error\n",
    "# NOTE:\n",
    "# you can increase the speed of this part slightly if you do not need to fit the datapreprocessor.\n",
    "# in that case, you would fit and apply the data preprocessor outside of this function and only fit the autoencoder inside the objective.\n",
    "def reconstruction_mse(trial: op.Trial) -> float:\n",
    "    \"\"\"Samples new hyperparameters. fits a new model and returns the reconstruction error (MSE) of the validation data.\n",
    "\n",
    "    Args:\n",
    "        trial: optuna Trial object\n",
    "\n",
    "    Returns:\n",
    "        MSE of the reconstruction.\n",
    "    \"\"\"\n",
    "\n",
    "    autoencoder_params = model_config.config_dict['train']['autoencoder']['params']\n",
    "\n",
    "    # sample new parameters\n",
    "    autoencoder_params['batch_size'] = int(trial.suggest_categorical(\n",
    "        name='batch_size', choices=[32, 64, 128]\n",
    "    ))\n",
    "    autoencoder_params['learning_rate'] = trial.suggest_float(\n",
    "        name='learning_rate', low=1e-5, high=0.01, log=True\n",
    "    )\n",
    "    autoencoder_params['decay_rate'] = trial.suggest_float(\n",
    "        name='decay_rate', low=0.8, high=0.99\n",
    "    )\n",
    "\n",
    "    # architecture\n",
    "    autoencoder_params['layers'][0] = trial.suggest_int(\n",
    "        name='layers_0', low=100, high=400\n",
    "    )\n",
    "    autoencoder_params['layers'][1] = trial.suggest_int(\n",
    "        name='layers_1', low=50, high=100\n",
    "    )\n",
    "    autoencoder_params['code_size'] = trial.suggest_int(\n",
    "        name='code_size', low=10, high=30\n",
    "    )\n",
    "\n",
    "    # update the configuration\n",
    "    model_config.update_config(model_config.config_dict)\n",
    "\n",
    "    # create a new model using our new configuration and train the model\n",
    "    model = FaultDetector(model_config)\n",
    "    # For autoencoder optimization, we do not need to fit a threshold\n",
    "    training_result = model.fit(train_data, normal_index=normal_index, fit_autoencoder_only=True, save_model=False)\n",
    "\n",
    "    # Calculate the MSE of the reconstruction errors of the validation data - this is minimized\n",
    "    deviations = training_result.val_recon_error\n",
    "    score = np.mean((np.square(deviations)))\n",
    "\n",
    "    return score"
   ],
   "id": "eadbdf08b64a43e4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "study = op.create_study(sampler=op.samplers.TPESampler(),\n",
    "                        study_name='autoencoder_optimization',\n",
    "                        direction='minimize')\n",
    "\n",
    "# if we want to ensure that the first trial is done with the hyperparameters of the configuration, we need to enqueue a trial:\n",
    "autoencoder_params = model_config.config_dict['train']['autoencoder']['params']\n",
    "study.enqueue_trial(params={\n",
    "    'batch_size': autoencoder_params['batch_size'],\n",
    "    'learning_rate': autoencoder_params['learning_rate'],\n",
    "    'decay_rate': autoencoder_params['decay_rate'],\n",
    "    'layers_0': autoencoder_params['layers'][0],\n",
    "    'layers_1': autoencoder_params['layers'][1],\n",
    "    'code_size': autoencoder_params['code_size'],\n",
    "})"
   ],
   "id": "ff13f4aeb3d8b6d0",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "study.optimize(reconstruction_mse, n_trials=5)"
   ],
   "id": "edfa14b97d00a0b9",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "study.best_params"
   ],
   "id": "91747046042e809a",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "# analyze results\n",
    "study.trials_dataframe()"
   ],
   "id": "4cf3e2b09291ba57",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Optimize fault detection model",
   "id": "cb3c07b2be2cb5ed"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "c2c = Care2CompareDataset(data_path)\n",
    "\n",
    "event_id = 47\n",
    "event_info = c2c.event_info_all[c2c.event_info_all['event_id'] == event_id].iloc[0]\n",
    "\n",
    "train_data, normal_index, test_data, test_normal_index = c2c.get_formatted_event_dataset(event_id=event_id, index_column='time_stamp')\n",
    "\n",
    "ground_truth = CAREScore.create_ground_truth(\n",
    "    event_label=event_info['event_label'],\n",
    "    event_start=event_info['event_start'],\n",
    "    event_end=event_info['event_end'],\n",
    "    normal_index=test_normal_index\n",
    ")"
   ],
   "id": "fa98c752d06b0e35",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "model_config = Config('c2c_configs/windfarm_C.yaml')  # starting point\n",
    "\n",
    "# speed up for testing\n",
    "N = 10000\n",
    "normal_index = normal_index.iloc[:N]\n",
    "train_data = train_data.iloc[:N]\n",
    "\n",
    "\n",
    "def f_score(trial: op.Trial) -> float:\n",
    "    \"\"\"Returns the F-score of the model (only useful for datasets with anomalies).\n",
    "\n",
    "    Args:\n",
    "        trial: optuna Trial object\n",
    "\n",
    "    Returns:\n",
    "        Score of the FaultDetector model \n",
    "    \"\"\"\n",
    "\n",
    "    dataprep_params = model_config.config_dict['train']['data_preprocessor']['params']\n",
    "    autoencoder_params = model_config.config_dict['train']['autoencoder']['params']\n",
    "\n",
    "    dataprep_params['scale'] = trial.suggest_categorical(\n",
    "        name='scale', choices=['minmax', 'standardize']\n",
    "    )\n",
    "\n",
    "    autoencoder_params['batch_size'] = int(trial.suggest_categorical(\n",
    "        name='batch_size', choices=[32, 64, 128]\n",
    "    ))\n",
    "    autoencoder_params['learning_rate'] = trial.suggest_float(\n",
    "        name='learning_rate', low=1e-5, high=0.01, log=True\n",
    "    )\n",
    "    autoencoder_params['decay_rate'] = trial.suggest_float(\n",
    "        name='decay_rate', low=0.8, high=0.99\n",
    "    )\n",
    "\n",
    "    # architecture\n",
    "    autoencoder_params['layers'][0] = trial.suggest_int(\n",
    "        name='layers_0', low=100, high=400\n",
    "    )\n",
    "    autoencoder_params['layers'][1] = trial.suggest_int(\n",
    "        name='layers_1', low=50, high=100\n",
    "    )\n",
    "    autoencoder_params['code_size'] = trial.suggest_int(\n",
    "        name='code_size', low=10, high=30\n",
    "    )\n",
    "\n",
    "    # update the configuration\n",
    "    model_config.update_config(model_config.config_dict)\n",
    "\n",
    "    # create a new model using our new configuration and train the model\n",
    "    model = FaultDetector(model_config)\n",
    "    _ = model.fit(train_data, normal_index=normal_index, save_models=False)\n",
    "    predictions = model.predict(test_data)\n",
    "\n",
    "    score = fbeta_score(\n",
    "        y_true=ground_truth.sort_index(),\n",
    "        y_pred=predictions.predicted_anomalies['anomaly'].sort_index(),\n",
    "        beta=0.5\n",
    "    )\n",
    "\n",
    "    return score"
   ],
   "id": "1651af56e86b8c17",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "study = op.create_study(sampler=op.samplers.TPESampler(),\n",
    "                        study_name='ad_optimization',\n",
    "                        direction='maximize')\n",
    "\n",
    "# if we want to ensure that the first trial is done with the hyperparameters of the configuration, we need to enqueue a trial:\n",
    "autoencoder_params = model_config.config_dict['train']['autoencoder']['params']\n",
    "study.enqueue_trial(params={\n",
    "    'batch_size': autoencoder_params['batch_size'],\n",
    "    'learning_rate': autoencoder_params['learning_rate'],\n",
    "    'decay_rate': autoencoder_params['decay_rate'],\n",
    "    'layers_0': autoencoder_params['layers'][0],\n",
    "    'layers_1': autoencoder_params['layers'][1],\n",
    "    'code_size': autoencoder_params['code_size'],\n",
    "})\n",
    "\n",
    "study.optimize(f_score, n_trials=5)"
   ],
   "id": "713d5956170a993e",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "study.trials_dataframe()"
   ],
   "id": "7b1b25ddfb3e5b2d",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "### Optimize CARE score\n",
    "Optimize the CARE Score. Note that this is extremely slow, as we train a model for each subdataset."
   ],
   "id": "bbdfaaaf03341cbc"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "wind_farm = 'B'\n",
    "model_config = Config('c2c_configs/windfarm_B.yaml')\n",
    "\n",
    "# speed up for testing\n",
    "N = 100\n",
    "\n",
    "def care_objective(trial: op.Trial) -> float:\n",
    "    \"\"\"Returns the F-score of the model (only useful for datasets with anomalies).\n",
    "\n",
    "    Args:\n",
    "        trial: optuna Trial object\n",
    "\n",
    "    Returns:\n",
    "        Score of the FaultDetector model.\n",
    "    \"\"\"\n",
    "\n",
    "    autoencoder_params = model_config.config_dict['train']['autoencoder']['params']\n",
    "    threshold_params = model_config.config_dict['train']['threshold_selector']['params']\n",
    "\n",
    "    autoencoder_params['batch_size'] = int(trial.suggest_categorical(\n",
    "        name='batch_size', choices=[32, 64, 128]\n",
    "    ))\n",
    "    autoencoder_params['learning_rate'] = trial.suggest_float(\n",
    "        name='learning_rate', low=1e-5, high=0.01, log=True\n",
    "    )\n",
    "\n",
    "    # architecture\n",
    "    autoencoder_params['layers'][0] = trial.suggest_int(\n",
    "        name='layers_0', low=20, high=100\n",
    "    )\n",
    "    autoencoder_params['code_size'] = trial.suggest_int(\n",
    "        name='code_size', low=5, high=20\n",
    "    )\n",
    "\n",
    "    # threshold\n",
    "    threshold_params['gamma'] = trial.suggest_float(name='gamma', low=0.05, high=0.3)\n",
    "    threshold_params['nn_size'] = trial.suggest_int(name='nn_size', low=20, high=50)\n",
    "\n",
    "    # update the configuration with the new hyperparameters\n",
    "    model_config.update_config(model_config.config_dict)\n",
    "\n",
    "    care_score = CAREScore(coverage_beta=0.5, eventwise_f_score_beta=0.5, anomaly_detection_method='criticality')\n",
    "    i = 1\n",
    "    for x_train, y_train, x_test, y_test, event_id in c2c.iter_formatted_datasets(wind_farm=wind_farm, index_column='time_stamp'):\n",
    "        print(f\"event {i}/{len(c2c.event_info_all[c2c.event_info_all['wind_farm'] == wind_farm])}\")\n",
    "        if N is not None:\n",
    "            x_train = x_train.iloc[:N]\n",
    "            x_test = x_test.iloc[:N]\n",
    "            y_train = y_train.iloc[:N]\n",
    "            y_test = y_test.iloc[:N]\n",
    "        \n",
    "        # create a new model using our new configuration and train the model\n",
    "        model = FaultDetector(model_config)\n",
    "        _ = model.fit(x_train, normal_index=y_train, save_models=False)\n",
    "        prediction = model.predict(x_test)\n",
    "        event_info = c2c.event_info_all[c2c.event_info_all['event_id'] == event_id].iloc[0]\n",
    "        care_score.evaluate_event(\n",
    "            event_id=event_id,\n",
    "            event_start=event_info['event_start'],\n",
    "            event_end=event_info['event_end'],\n",
    "            event_label=event_info['event_label'],\n",
    "            normal_index=y_test,\n",
    "            predicted_anomalies=prediction.predicted_anomalies['anomaly'],\n",
    "            ignore_normal_index=False\n",
    "        )\n",
    "        i += 1\n",
    "\n",
    "    score = care_score.get_final_score()\n",
    "\n",
    "    return score"
   ],
   "id": "7cee58426b72d9a4",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "study = op.create_study(sampler=op.samplers.TPESampler(),\n",
    "                        study_name='care_optimization',\n",
    "                        direction='maximize')\n",
    "\n",
    "# Ensure that the first trial is done with the hyperparameters of the provided configuration\n",
    "autoencoder_params = model_config.config_dict['train']['autoencoder']['params']\n",
    "threshold_params = model_config.config_dict['train']['threshold_selector']['params']\n",
    "study.enqueue_trial(params={\n",
    "    'batch_size': autoencoder_params['batch_size'],\n",
    "    'learning_rate': autoencoder_params['learning_rate'],\n",
    "    'layers_0': autoencoder_params['layers'][0],\n",
    "    'code_size': autoencoder_params['code_size'],\n",
    "    'gamma': threshold_params['gamma'],\n",
    "    'nn_size': threshold_params['nn_size'],\n",
    "})\n",
    "\n",
    "# since we loop through many datasets, train many models, we run the garbage collector after each trial\n",
    "study.optimize(care_objective, n_trials=5, gc_after_trial=True)"
   ],
   "id": "6621d7a2bf3ac717",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "study.trials_dataframe()"
   ],
   "id": "9aa3d678f4fa22e3",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
